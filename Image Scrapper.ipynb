{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf5dfdf-e39a-470f-8c44-c74e1e99b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad32690-43fe-4ce8-9c05-b095f8ba3468",
   "metadata": {},
   "source": [
    "# Q-1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48df6604-d362-48f4-870b-70bebba6b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "video_urls = []\n",
    "for container in video_containers[:5]:\n",
    "    link_element = container.find(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    if link_element is not None and \"href\" in link_element.attrs:\n",
    "        video_url = \"https://www.youtube.com\" + link_element[\"href\"]\n",
    "        video_urls.append(video_url)\n",
    "\n",
    "# Print the extracted video URLs\n",
    "for i, video_url in enumerate(video_urls):\n",
    "    print(f\"Video {i+1}: {video_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0305bad-52a2-4ddc-930c-caeb2c1544d6",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08546e11-48b5-46bd-8e83-0228d197d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the URLs of the video thumbnails of the first five videos\n",
    "thumbnail_urls = []\n",
    "for container in video_containers[:5]:\n",
    "    thumbnail_element = container.find(\"img\", class_=\"style-scope yt-img-shadow\")\n",
    "    if thumbnail_element is not None and \"src\" in thumbnail_element.attrs:\n",
    "        thumbnail_url = thumbnail_element[\"src\"]\n",
    "        thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Print the extracted thumbnail URLs\n",
    "for i, thumbnail_url in enumerate(thumbnail_urls):\n",
    "    print(f\"Thumbnail {i+1}: {thumbnail_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61f331-1290-41c2-9c22-aae1bf9f1805",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066e0677-4c35-4f00-9319-d377f942399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "video_titles = []\n",
    "for container in video_containers[:5]:\n",
    "    title_element = container.find(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    if title_element is not None and \"title\" in title_element.attrs:\n",
    "        video_title = title_element[\"title\"]\n",
    "        video_titles.append(video_title)\n",
    "\n",
    "# Print the extracted video titles\n",
    "for i, video_title in enumerate(video_titles):\n",
    "    print(f\"Video {i+1} title: {video_title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0ad08-2343-4c04-bdad-1074dddee8ce",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67abb906-094e-4562-93f0-a04de5e2a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "view_counts = []\n",
    "for container in video_containers[:5]:\n",
    "    view_count_element = container.find(\"span\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    if view_count_element is not None:\n",
    "        view_count = view_count_element.get_text().strip()\n",
    "        view_counts.append(view_count)\n",
    "\n",
    "# Print the extracted view counts\n",
    "for i, view_count in enumerate(view_counts):\n",
    "    print(f\"Video {i+1} views: {view_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f38b02-2a03-4228-ac5c-4d5fdc28b9ac",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c514d19-a4f1-4681-b8ee-d2b93fbb910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the time of posting for the first five videos\n",
    "posting_times = []\n",
    "for container in video_containers[:5]:\n",
    "    time_element = container.find(\"span\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    if time_element is not None:\n",
    "        posting_time = time_element.get_text().strip()\n",
    "        posting_times.append(posting_time)\n",
    "\n",
    "# Print the extracted posting times\n",
    "for i, posting_time in enumerate(posting_times):\n",
    "    print(f\"Video {i+1} posted: {posting_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b098b-1287-4a82-a1f8-d3dd52478e66",
   "metadata": {},
   "source": [
    "# Save the all Data in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8efdd93-7907-4df0-8909-0cdece3ff3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been scraped and saved to video_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find all the video containers on the page\n",
    "video_containers = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "\n",
    "# Extract the desired information for the first five videos\n",
    "data = []\n",
    "for container in video_containers[:5]:\n",
    "    # Extract video URL\n",
    "    video_url_element = container.find(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    if video_url_element is not None and \"href\" in video_url_element.attrs:\n",
    "        video_url = \"https://www.youtube.com\" + video_url_element[\"href\"]\n",
    "    else:\n",
    "        video_url = \"\"\n",
    "\n",
    "    # Extract video thumbnail URL\n",
    "    thumbnail_element = container.find(\"img\", class_=\"style-scope yt-img-shadow\")\n",
    "    if thumbnail_element is not None and \"src\" in thumbnail_element.attrs:\n",
    "        thumbnail_url = thumbnail_element[\"src\"]\n",
    "    else:\n",
    "        thumbnail_url = \"\"\n",
    "\n",
    "    # Extract video title\n",
    "    title_element = container.find(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    if title_element is not None and \"title\" in title_element.attrs:\n",
    "        title = title_element[\"title\"]\n",
    "    else:\n",
    "        title = \"\"\n",
    "\n",
    "    # Extract number of views\n",
    "    view_count_element = container.find(\"span\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    if view_count_element is not None:\n",
    "        view_count = view_count_element.get_text().strip()\n",
    "    else:\n",
    "        view_count = \"\"\n",
    "\n",
    "    # Extract time of posting\n",
    "    time_element = container.find(\"span\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    if time_element is not None:\n",
    "        posting_time = time_element.get_text().strip()\n",
    "    else:\n",
    "        posting_time = \"\"\n",
    "\n",
    "    # Append the extracted data to the list\n",
    "    data.append([video_url, thumbnail_url, title, view_count, posting_time])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "csv_file = \"video_data.csv\"\n",
    "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Video URL\", \"Thumbnail URL\", \"Title\", \"Views\", \"Posting Time\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
